// Changes:
// - removed /crex/proj/naiss2023-22-866/

params {
	//Path to working directory including fastq.gz files
	workDir="MetONTIIME/trimmed_and_filtered_Q15_qz"
	//Path to database file with sequences in fasta format
	dbSequencesFasta="Illumina_Qiime2_and_BLAST/sh_refs_qiime_ver9_dynamic_all_25.07.2023.fasta"
	//Path to database file with sequence id-to-taxonomy correspondence in tsv format
	dbSequencesQza="db_sequences.qza"
	dbTaxonomyQza="db_taxonomy.qza"
	dbTaxonomyTsv="MetONTIIME/noheader_taxonomy_qiime_ver9_dynamic_alleukaryotes_25.07.2023.tsv"
	//Taxonomy classifier, available: VSEARCH, Blast
	classifier="Vsearch"
	//Identity for de novo clustering [0-1]
	clusteringIdentity=0.97
	//Maximum number of candidate hits for each read, to be used for consensus taxonomy assignment
	maxAccepts=3
	//Minimum fraction of assignments must match top hit to be accepted as consensus assignment [0.5-1]
    minConsensus=0.7
	//Minimum query coverage for an alignment to be considered a candidate hit [0-1]
	minQueryCoverage=0.8
	//Minimum alignment identity for an alignment to be considered a candidate hit [0-1]
	minIdentity=0.9
	//Taxonomy level at which you want to perform non-phylogeny-based diversity analyses
	taxaLevelDiversity=6
	//Path to directory containing results
	resultsDir="MetONTIIME/Output"

	help=false

	// Flags to select which process to run
	concatenateFastq = false
	filterFastq = false
	downsampleFastq = false
	importFastq = true
	dataQC = true
	importDb = true
	derepSeq = true
	assignTaxonomy = true
	taxonomyVisualization = true
	collapseTables = true
	filterTaxa = false
	diversityAnalyses = true
}

tower {
	enabled = false
	endpoint = '-'
	accessToken = 'nextflowTowerToken'
}

profiles {
	singularity {
		singularity.enabled = true
		singularity.autoMounts = false
		//singularity.cacheDir = "MetONTIIME" // if commented, work dir is going to be usedd

		process{
			containerOptions = '--bind MetONTIIME/:MetONTIIME'
			cpus = 1
			executor = 'slurm'
			//queue = 'workq'
			perJobMemLimit = true
			withName:concatenateFastq{
				container = 'maestsi/metontiime:latest'
				cpus = { params.concatenateFastq ? 6 : 1 }
				memory = { params.concatenateFastq ? 10.GB + (2.GB * (task.attempt-1)) : 1.GB }
				errorStrategy = { task.exitStatus == 130 ? 'retry' : 'terminate' }
				maxRetries = 3
			}
			withName:filterFastq{
				container = 'maestsi/metontiime:latest'
				cpus = { params.filterFastq ? 6 : 1 }
				memory = { params.filterFastq ? 5.GB + (2.GB * (task.attempt-1)) : 1.GB }
				errorStrategy = { task.exitStatus == 130 ? 'retry' : 'terminate' }
				maxRetries = 3
			}
			withName:downsampleFastq{
				container = 'maestsi/metontiime:latest'
				cpus = { params.downsampleFastq ? 6 : 1 }
				memory = { params.downsampleFastq ? 10.GB + (2.GB * (task.attempt-1)) : 1.GB }
				errorStrategy = { task.exitStatus == 130 ? 'retry' : 'terminate' }
				maxRetries = 3
			}
			withName:importFastq{
				container = 'maestsi/metontiime:latest'
				cpus = { params.importFastq ? 6 : 1 }
				memory = { params.importFastq ? 256.GB + (2.GB * (task.attempt-1)) : 1.GB }
				errorStrategy = { task.exitStatus == 130 ? 'retry' : 'terminate' }
				maxRetries = 3
			}
			withName:dataQC{
				container = 'maestsi/metontiime:latest'
				cpus = { params.dataQC ? 6 : 1 }
				memory = { params.dataQC ? 256.GB + (2.GB * (task.attempt-1)) : 1.GB }
				errorStrategy = { task.exitStatus == 130 ? 'retry' : 'terminate' }
				maxRetries = 3
			}
			withName:importDb{
				container = 'maestsi/metontiime:latest'
				cpus = { params.importDb ? 6 : 1 }
				memory = { params.importDb ? 10.GB + (2.GB * (task.attempt-1)) : 1.GB }
				errorStrategy = { task.exitStatus == 130 ? 'retry' : 'terminate' }
				maxRetries = 3
			}
			withName:derepSeq{
				container = 'maestsi/metontiime:latest'
				cpus = { params.derepSeq ? 6 : 1 }
				memory = { params.derepSeq ? 256.GB + (2.GB * (task.attempt-1)) : 1.GB }
				errorStrategy = { task.exitStatus == 130 ? 'retry' : 'terminate' }
				maxRetries = 3
			}
			withName:assignTaxonomy{
				container = 'maestsi/metontiime:latest'
				cpus = { params.assignTaxonomy ? 6 : 1 }
				memory = { params.assignTaxonomy ? 256.GB + (2.GB * (task.attempt-1)) : 1.GB }
				errorStrategy = { task.exitStatus == 130 ? 'retry' : 'terminate' }
				maxRetries = 3
			}
			withName:taxonomyVisualization{
				container = 'maestsi/metontiime:latest'
				cpus = { params.taxonomyVisualization ? 6 : 1 }
				memory = { params.taxonomyVisualization ? 256.GB + (2.GB * (task.attempt-1)) : 1.GB }
				errorStrategy = { task.exitStatus == 130 ? 'retry' : 'terminate' }
				maxRetries = 3
			}
			withName:collapseTables{
				container = 'maestsi/metontiime:latest'
				cpus = { params.collapseTables ? 6 : 1 }
				memory = { params.collapseTables ? 256.GB + (2.GB * (task.attempt-1)) : 1.GB }
				errorStrategy = { task.exitStatus == 130 ? 'retry' : 'terminate' }
				maxRetries = 3
			}
			withName:filterTaxa{
				container = 'maestsi/metontiime:latest'
				cpus = { params.filterTaxa ? 6 : 1 }
				memory = { params.filterTaxa ? 256.GB + (2.GB * (task.attempt-1)) : 1.GB }
				errorStrategy = { task.exitStatus == 130 ? 'retry' : 'terminate' }
				maxRetries = 3
			}
			withName:diversityAnalyses{
				container = 'maestsi/metontiime:latest'
				cpus = { params.diversityAnalyses ? 6 : 1 }
				memory = { params.diversityAnalyses ? 256.GB + (2.GB * (task.attempt-1)) : 1.GB }
				errorStrategy = { task.exitStatus == 130 ? 'retry' : 'terminate' }
				maxRetries = 3
			}
		}
	}
}

profiles {
	devel {
		params {
			config_profile_description = 'Testing & development profile for UPPMAX, provided by nf-core/configs.'
			// Max resources to be requested by a devel job
			max_memory = 120.GB
			max_time = 1.h
		}
		executor.queueSize = 1
		process.queue = 'devel'
	}
}

profiles {
    uppmax {
        // UPPMAX Config Profile
		params {
			// Description is overwritten for other clusters below
			config_profile_description = 'UPPMAX (Bianca) cluster profile provided by nf-core/configs.'
			config_profile_contact = 'Phil Ewels (@ewels)'
			config_profile_url = 'https://www.uppmax.uu.se/'
			project = null
			clusterOptions = null
			schema_ignore_params = "genomes,input_paths,cluster-options,clusterOptions,project"
			validationSchemaIgnoreParams = "genomes,input_paths,cluster-options,clusterOptions,project,schema_ignore_params"
			save_reference = true
			// Defaults set for Bianca - other clusters set below
			max_memory = 500.GB
			max_cpus = 16
			max_time = 240.h
			// illumina iGenomes reference file paths on UPPMAX
			igenomes_base = '/sw/data/igenomes/'
		}

		singularity {
			enabled = true
			envWhitelist = 'SNIC_TMP'
		}

		def hostname = "r1"
		try {
			hostname = ['/bin/bash', '-c', 'sinfo --local -N -h | grep -m 1 -F -v CLUSTER: | cut -f1 -d" "'].execute().text.trim()
		} catch (java.io.IOException e) {
			System.err.println("WARNING: Could not run sinfo to determine current cluster, defaulting to rackham")
		}

		// closure to create a suitable clusterOptions
		def clusterOptionsCreator = { m ->
			String base = "-A $params.project ${params.clusterOptions ?: ''}"
			// Do not use -p node on irma or if a thin node/core is enough
			if (m <= 125.GB || hostname.startsWith("i")) {
				return base
			}

			// cluster is miarka
			if (hostname.startsWith("m")) {
				// job will fit on a regular node
				if (m <= 357.GB) {
					return base
				}
				// job requires at least a 2TB node
				if (m <= 2000.GB) {
					return base + " --mem 2TB "
				}
				// job requires the largest node
				return base + " -C mem4TB "
			}

			if (m <= 250.GB) {
				return base + " -p node -C mem256GB "
			}


			// Use mem1TB for remaining cases on rackham (no 512 Gbyte nodes)
			if (hostname.startsWith("r")) {
				return base + " -p node -C mem1TB "
			}

			if (m > 500.GB) {
				// Special case for snowy very fat node (only remaining case that's above 500 GB)
				return base + " -p veryfat "
			}

			// Should only be cases for mem512GB left (snowy and bianca)
			return base + " -p node -C mem512GB "
		}

		process {
			executor = 'slurm'
			clusterOptions = { clusterOptionsCreator(task.memory) }
			// Use node local storage for execution.
			scratch = '$SNIC_TMP'
		}

		// Cluster: Rackham
		if (hostname.startsWith("r")) {
			params.max_cpus = 20
			params.max_memory = 970.GB
			params.config_profile_description = 'UPPMAX (Rackham) cluster profile provided by nf-core/configs.'
		}

		// Cluster: Bianca - set in initial params block above

		// Additional devel profile for running in devel queue
		// Run with `-profile upppmax,devel`
    }
}
